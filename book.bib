@article{allen_1997,
  title = {Effects of {{Variable Recruitment}} on {{Catch-Curve Analysis}} for {{Crappie Populations}}},
  author = {Allen, M. S.},
  date = {1997},
  journaltitle = {North American Journal of Fisheries Management},
  volume = {17},
  number = {1},
  pages = {202--205},
  issn = {1548-8675},
  doi = {10.1577/1548-8675(1997)017<0202:EOVROC>2.3.CO;2},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1577/1548-8675%281997%29017%3C0202%3AEOVROC%3E2.3.CO%3B2},
  urldate = {2023-11-05},
  abstract = {Catch-curve analysis is frequently used to estimate total annual mortality (A) of exploited fishes, but the method assumes constant recruitment. Because populations of crappie Pomoxis spp. have exhibited large fluctuations in recruitment, I conducted simulations to assess the amount of variability in recruitment that precludes the use of a catch curve and compared results to recruitment dynamics in six crappie populations. Coefficients of variation (CV = 100.SD/mean) in recruitment to age 1 ranged from 55\% to 84\% among the six crappie populations. Simulations suggested that recruitment variability in these ranges would likely allow estimation of A within ± 10\%, but the probability of obtaining estimates of A that were ±5\% or more of the true A would exceed 0.15. 1 suggest that catch curves may be used to approximate A in crappie populations but that managers should consider the effects on management recommendations if A were ± 10\% of the estimated A.},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\U3BPYTBL\\Allen - 1997 - Effects of Variable Recruitment on Catch-Curve Ana.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\2VF9RGPB\\1548-8675(1997)0170202EOVROC2.3.html}
}

@book{bolker2008,
  title = {Ecological {{Models}} and {{Data}} in {{R}}},
  author = {Bolker, Benjamin M.},
  date = {2008},
  edition = {1},
  publisher = {Princeton University Press},
  location = {Princeton, New Jersey}
}

@article{brooks.gelman1998,
  title = {General {{Methods}} for {{Monitoring Convergence}} of {{Iterative Simulations}}},
  author = {Brooks, Stephen P. and Gelman, Andrew},
  date = {1998-12-01},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {7},
  number = {4},
  pages = {434--455},
  publisher = {Taylor \& Francis},
  issn = {1061-8600},
  doi = {10.1080/10618600.1998.10474787},
  url = {https://www.tandfonline.com/doi/abs/10.1080/10618600.1998.10474787},
  urldate = {2022-01-31},
  abstract = {We generalize the method proposed by Gelman and Rubin (1992a) for monitoring the convergence of iterative simulations by comparing between and within variances of multiple chains, in order to obtain a family of tests for convergence. We review methods of inference from simulations in order to develop convergence-monitoring summaries that are relevant for the purposes for which the simulations are used. We recommend applying a battery of tests for mixing based on the comparison of inferences from individual sequences and from the mixture of sequences. Finally, we discuss multivariate analogues, for assessing convergence of several parameters simultaneously.},
  keywords = {Convergence diagnosis,Inference,Markov chain Monte Carlo},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\ZK3P5J8X\\Brooks and Gelman - 1998 - General Methods for Monitoring Convergence of Iter.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\ZLRS57HH\\10618600.1998.html}
}

@report{brownie.etal1985,
  type = {Federal Government Series},
  title = {Statistical Inference from Band Recovery Data: A Handbook},
  shorttitle = {Statistical Inference from Band Recovery Data},
  author = {Brownie, Cavell and Anderson, D.R. and Burnham, K.P. and Robson, D.S.},
  date = {1985},
  series = {Resource {{Publication}}},
  number = {156},
  institution = {{U.S. Fish and Wildlife}},
  location = {Washington, D.C.},
  url = {http://pubs.er.usgs.gov/publication/rp156},
  urldate = {2022-04-11},
  abstract = {No abstract available.}
}

@article{bryant2000,
  title = {Estimating {{Fish Populations}} by {{Removal Methods}} with {{Minnow Traps}} in {{Southeast Alaska Streams}}},
  author = {Bryant, Mason D.},
  date = {2000-11},
  journaltitle = {North American Journal of Fisheries Management},
  shortjournal = {North American Journal of Fisheries Management},
  volume = {20},
  number = {4},
  pages = {923--930},
  issn = {0275-5947, 1548-8675},
  doi = {10.1577/1548-8675(2000)020<0923:EFPBRM>2.0.CO;2},
  url = {http://doi.wiley.com/10.1577/1548-8675(2000)020<0923:EFPBRM>2.0.CO;2},
  urldate = {2022-02-10},
  abstract = {Passive capture methods, such as minnow traps, are commonly used to capture fish for mark-recapture population estimates; however, they have not been used for removal methods. Minnow traps set for 90-min periods during three or four sequential capture occasions during the summer of 1996 were used to capture coho salmon Oncorhynchus kisutch fry and parr, Dolly Varden Salvelinus malma, cutthroat trout O. clarki, and juvenile steelhead O. mykiss to estimate population size with the Zippin or generalized removal method. More than 45\% of the total catch was obtained during the first capture occasion, and in most cases, the catch during the fourth occasion was less than 15\% of the total catch. In most pools, the probability of capture was greater than 0.4 but was lower for coho salmon fry than for coho salmon parr and other species. Mean population estimates for coho salmon parr made with concurrent mark-recapture and removal methods differed significantly in small streams. Estimates from mark-recapture and removal methods were not significantly different for coho salmon fry and Dolly Varden, but mark-recapture estimates were higher than removal estimates in most cases. My results show that removal estimates can be obtained with minnow traps if sampling procedures conform to the assumptions required for the method.},
  langid = {english},
  file = {C:\Users\jhncsu\Zotero\storage\EL5DAMDI\Bryant - 2000 - Estimating Fish Populations by Removal Methods wit.pdf}
}

@book{burnham.anderson_2004,
  title = {Model {{Selection}} and {{Multimodel Inference}}},
  editor = {Burnham, Kenneth P. and Anderson, David R.},
  date = {2004},
  publisher = {Springer},
  location = {New York, NY},
  doi = {10.1007/b97636},
  url = {http://link.springer.com/10.1007/b97636},
  urldate = {2023-12-06},
  isbn = {978-0-387-95364-9},
  langid = {english},
  keywords = {data analysis,Estimator,Inference,information theory,Likelihood,Model Selection},
  file = {C:\Users\jhncsu\Zotero\storage\PZSJUIRD\Burnham and Anderson - 2004 - Model Selection and Multimodel Inference.pdf}
}

@article{campana2001,
  title = {Accuracy, Precision and Quality Control in Age Determination, Including a Review of the Use and Abuse of Age Validation Methods},
  author = {Campana, S. E.},
  date = {2001},
  journaltitle = {Journal of Fish Biology},
  volume = {59},
  number = {2},
  pages = {197--242},
  issn = {1095-8649},
  doi = {10.1111/j.1095-8649.2001.tb00127.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1095-8649.2001.tb00127.x},
  urldate = {2023-02-23},
  abstract = {Many calcified structures produce periodic growth increments useful for age determination at the annual or daily scale. However, age determination is invariably accompanied by various sources of error, some of which can have a serious effect on age-structured calculations. This review highlights the best available methods for insuring ageing accuracy and quantifying ageing precision, whether in support of large-scale production ageing or a small-scale research project. Included in this review is a critical overview of methods used to initiate and pursue an accurate and controlled ageing program, including (but not limited to) validation of an ageing method. The distinction between validation of absolute age and increment periodicity is emphasized, as is the importance of determining the age of first increment formation. Based on an analysis of 372 papers reporting age validation since 1983, considerable progress has been made in age validation efforts in recent years. Nevertheless, several of the age validation methods which have been used routinely are of dubious value, particularly marginal increment analysis. The two major measures of precision, average percent error and coefficient of variation, are shown to be functionally equivalent, and a conversion factor relating the two is presented. Through use of quality control monitoring, ageing errors are readily detected and quantified; reference collections are the key to both quality control and reduction of costs. Although some level of random ageing error is unavoidable, such error can often be corrected after the fact using statistical (‘digital sharpening)’ methods.},
  langid = {english},
  keywords = {accuracy,age determination,otolith,precision,quality,validation},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\P5XG854R\\Campana - 2001 - Accuracy, precision and quality control in age det.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\7ZILP8N8\\j.1095-8649.2001.tb00127.html}
}

@article{conn.etal_2008,
  title = {Bayesian {{Analysis}} of {{Wildlife Age-at-Harvest Data}}},
  author = {Conn, Paul B. and Diefenbach, Duane R. and Laake, Jeffrey L. and Ternent, Mark A. and White, Gary C.},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  number = {4},
  pages = {1170--1177},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2008.00987.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2008.00987.x},
  urldate = {2024-02-06},
  abstract = {State and federal natural resource management agencies often collect age-structured harvest data. These data represent finite realizations of stochastic demographic and sampling processes and have long been used by biologists to infer population trends. However, different sources of data have been combined in ad hoc ways and these methods usually failed to incorporate sampling error. In this article, we propose a “hidden process” (or state-space) model for estimating abundance, survival, recovery rate, and recruitment from age-at-harvest data that incorporate both demographic and sampling stochasticity. To this end, a likelihood for age-at-harvest data is developed by embedding a population dynamics model within a model for the sampling process. Under this framework, the identification of abundance parameters can be achieved by conducting a joint analysis with an auxiliary data set. We illustrate this approach by conducting a Bayesian analysis of age-at-harvest and mark-recovery data from black bears (Ursus americanus) in Pennsylvania. Using a set of reasonable prior distributions, we demonstrate a substantial increase in precision when posterior summaries of abundance are compared to a bias-corrected Lincoln–Petersen estimator. Because demographic processes link consecutive abundance estimates, we also obtain a more realistic biological picture of annual changes in abundance. Because age-at-harvest data are often readily obtained, we argue that this type of analysis provides a valuable strategy for wildlife population monitoring.},
  langid = {english},
  keywords = {Abundance,Age-at-harvest,Black bear,Cohort model,Mark-recovery model,Recruitment,State-space model,Survival},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\W8GK2BTP\\Conn et al. - 2008 - Bayesian Analysis of Wildlife Age-at-Harvest Data.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\I3R5E49F\\j.1541-0420.2008.00987.html}
}

@article{conn.etal_2018,
  title = {A Guide to {{Bayesian}} Model Checking for Ecologists},
  author = {Conn, Paul B. and Johnson, Devin S. and Williams, Perry J. and Melin, Sharon R. and Hooten, Mevin B.},
  date = {2018},
  journaltitle = {Ecological Monographs},
  volume = {88},
  number = {4},
  pages = {526--542},
  issn = {1557-7015},
  doi = {10.1002/ecm.1314},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ecm.1314},
  urldate = {2023-12-15},
  abstract = {Checking that models adequately represent data is an essential component of applied statistical inference. Ecologists increasingly use hierarchical Bayesian statistical models in their research. The appeal of this modeling paradigm is undeniable, as researchers can build and fit models that embody complex ecological processes while simultaneously accounting for observation error. However, ecologists tend to be less focused on checking model assumptions and assessing potential lack of fit when applying Bayesian methods than when applying more traditional modes of inference such as maximum likelihood. There are also multiple ways of assessing the fit of Bayesian models, each of which has strengths and weaknesses. For instance, Bayesian P values are relatively easy to compute, but are well known to be conservative, producing P values biased toward 0.5. Alternatively, lesser known approaches to model checking, such as prior predictive checks, cross-validation probability integral transforms, and pivot discrepancy measures may produce more accurate characterizations of goodness-of-fit but are not as well known to ecologists. In addition, a suite of visual and targeted diagnostics can be used to examine violations of different model assumptions and lack of fit at different levels of the modeling hierarchy, and to check for residual temporal or spatial autocorrelation. In this review, we synthesize existing literature to guide ecologists through the many available options for Bayesian model checking. We illustrate methods and procedures with several ecological case studies including (1) analysis of simulated spatiotemporal count data, (2) N-mixture models for estimating abundance of sea otters from an aircraft, and (3) hidden Markov modeling to describe attendance patterns of California sea lion mothers on a rookery. We find that commonly used procedures based on posterior predictive P values detect extreme model inadequacy, but often do not detect more subtle cases of lack of fit. Tests based on cross-validation and pivot discrepancy measures (including the “sampled predictive P value”) appear to be better suited to model checking and to have better overall statistical performance. We conclude that model checking is necessary to ensure that scientific inference is well founded. As an essential component of scientific discovery, it should accompany most Bayesian analyses presented in the literature.},
  langid = {english},
  keywords = {Bayesian model checking,Bayesian P value,goodness-of-fit,hierarchical model,model diagnostics,posterior checks},
  file = {C:\Users\jhncsu\Zotero\storage\7PZV2J6X\ecm.html}
}

@article{devalpine.etal_2017,
  title = {Programming {{With Models}}: {{Writing Statistical Algorithms}} for {{General Model Structures With NIMBLE}}},
  shorttitle = {Programming {{With Models}}},
  author = {family=Valpine, given=Perry, prefix=de, useprefix=true and Turek, Daniel and Paciorek, Christopher J. and Anderson-Bergman, Clifford and Lang, Duncan Temple and Bodik, Rastislav},
  date = {2017-04-03},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {26},
  number = {2},
  pages = {403--413},
  publisher = {Taylor \& Francis},
  issn = {1061-8600},
  doi = {10.1080/10618600.2016.1172487},
  url = {https://doi.org/10.1080/10618600.2016.1172487},
  urldate = {2024-04-08},
  abstract = {We describe NIMBLE, a system for programming statistical algorithms for general model structures within R. NIMBLE is designed to meet three challenges: flexible model specification, a language for programming algorithms that can use different models, and a balance between high-level programmability and execution efficiency. For model specification, NIMBLE extends the BUGS language and creates model objects, which can manipulate variables, calculate log probability values, generate simulations, and query the relationships among variables. For algorithm programming, NIMBLE provides functions that operate with model objects using two stages of evaluation. The first stage allows specialization of a function to a particular model and/or nodes, such as creating a Metropolis-Hastings sampler for a particular block of nodes. The second stage allows repeated execution of computations using the results of the first stage. To achieve efficient second-stage computation, NIMBLE compiles models and functions via C++, using the Eigen library for linear algebra, and provides the user with an interface to compiled objects. The NIMBLE language represents a compilable domain-specific language (DSL) embedded within R. This article provides an overview of the design and rationale for NIMBLE along with illustrative examples including importance sampling, Markov chain Monte Carlo (MCMC) and Monte Carlo expectation maximization (MCEM). Supplementary materials for this article are available online.},
  keywords = {Domain-specific language,Hierarchical models,MCEM,MCMC,Probabilistic programming,R},
  file = {C:\Users\jhncsu\Zotero\storage\D75HKLPA\de Valpine et al. - 2017 - Programming With Models Writing Statistical Algor.pdf}
}

@article{doll.jacquemin_2018,
  title = {Introduction to {{Bayesian Modeling}} and {{Inference}} for {{Fisheries Scientists}}},
  author = {Doll, Jason C. and Jacquemin, Stephen J.},
  date = {2018},
  journaltitle = {Fisheries},
  volume = {43},
  number = {3},
  pages = {152--161},
  issn = {1548-8446},
  doi = {10.1002/fsh.10038},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/fsh.10038},
  urldate = {2024-02-15},
  abstract = {Bayesian inference is everywhere, from one of the most recent journal articles in Transactions of the American Fisheries Society to the decision-making process you undergo when selecting a new fishing spot. Bayesian inference is the only statistical paradigm that synthesizes prior knowledge with newly collected data to facilitate a more informed decision—and it is being used at an increasing rate in almost every area of our profession. Thus, the goal of this article is to provide fisheries managers, educators, and students with a conceptual introduction to Bayesian inference. We do not assume that the reader is familiar with Bayesian inference; however, we do assume that the reader has completed an introductory biostatistics course. To this end, we review the conceptual foundation of Bayesian inference without the use of complex equations; present one example of using Bayesian inference to compare relative weight between two time periods; present one example of using prior information about von Bertalanffy growth parameters to improve parameter estimation; and, finally, suggest literature that can help to develop the skills needed to use Bayesian inference in your own management or research program.},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\H8JJQM2Q\\Doll and Jacquemin - 2018 - Introduction to Bayesian Modeling and Inference fo.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\SP7SBPER\\fsh.html}
}

@article{dorazio_2016,
  title = {Bayesian Data Analysis in Population Ecology: Motivations, Methods, and Benefits},
  shorttitle = {Bayesian Data Analysis in Population Ecology},
  author = {Dorazio, Robert M.},
  date = {2016},
  journaltitle = {Population Ecology},
  volume = {58},
  number = {1},
  pages = {31--44},
  issn = {1438-390X},
  doi = {10.1007/s10144-015-0503-4},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1007/s10144-015-0503-4},
  urldate = {2023-10-15},
  abstract = {During the 20th century ecologists largely relied on the frequentist system of inference for the analysis of their data. However, in the past few decades ecologists have become increasingly interested in the use of Bayesian methods of data analysis. In this article I provide guidance to ecologists who would like to decide whether Bayesian methods can be used to improve their conclusions and predictions. I begin by providing a concise summary of Bayesian methods of analysis, including a comparison of differences between Bayesian and frequentist approaches to inference when using hierarchical models. Next I provide a list of problems where Bayesian methods of analysis may arguably be preferred over frequentist methods. These problems are usually encountered in analyses based on hierarchical models of data. I describe the essentials required for applying modern methods of Bayesian computation, and I use real-world examples to illustrate these methods. I conclude by summarizing what I perceive to be the main strengths and weaknesses of using Bayesian methods to solve ecological inference problems.},
  langid = {english},
  keywords = {Frequentist inference,Hierarchical modeling,Missing data,Occupancy model,Spatial analysis,State-space modeling},
  file = {C:\Users\jhncsu\Zotero\storage\KWESD48P\s10144-015-0503-4.html}
}

@book{efron.tibshirani_1993,
  title = {An {{Introduction}} to the {{Bootstrap}}},
  author = {Efron, Bradley and Tibshirani, R. J.},
  date = {1993-01-01},
  edition = {1st edition},
  publisher = {{Chapman and Hall/CRC}},
  location = {Boca Raton, Fla.},
  abstract = {Statistics is a subject of many uses and surprisingly few effective practitioners. The traditional road to statistical knowledge is blocked, for most, by a formidable wall of mathematics. The approach in An Introduction to the Bootstrap avoids that wall. It arms scientists and engineers, as well as statisticians, with the computational techniques they need to analyze and understand complicated data sets.},
  isbn = {978-0-412-04231-7},
  langid = {english},
  pagetotal = {456}
}

@article{ellison_2004,
  title = {Bayesian Inference in Ecology},
  author = {Ellison, Aaron M.},
  date = {2004},
  journaltitle = {Ecology Letters},
  volume = {7},
  number = {6},
  pages = {509--520},
  issn = {1461-0248},
  doi = {10.1111/j.1461-0248.2004.00603.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1461-0248.2004.00603.x},
  urldate = {2023-10-17},
  abstract = {Bayesian inference is an important statistical tool that is increasingly being used by ecologists. In a Bayesian analysis, information available before a study is conducted is summarized in a quantitative model or hypothesis: the prior probability distribution. Bayes’ Theorem uses the prior probability distribution and the likelihood of the data to generate a posterior probability distribution. Posterior probability distributions are an epistemological alternative to P-values and provide a direct measure of the degree of belief that can be placed on models, hypotheses, or parameter estimates. Moreover, Bayesian information-theoretic methods provide robust measures of the probability of alternative models, and multiple models can be averaged into a single model that reflects uncertainty in model construction and selection. These methods are demonstrated through a simple worked example. Ecologists are using Bayesian inference in studies that range from predicting single-species population dynamics to understanding ecosystem processes. Not all ecologists, however, appreciate the philosophical underpinnings of Bayesian inference. In particular, Bayesians and frequentists differ in their definition of probability and in their treatment of model parameters as random variables or estimates of true values. These assumptions must be addressed explicitly before deciding whether or not to use Bayesian methods to analyse ecological data.},
  langid = {english},
  keywords = {Bayes’ Theorem,Bayesian inference,epistemology,information criteria,model averaging,model selection},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\AJCLBLXD\\Ellison - 2004 - Bayesian inference in ecology.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\KGJ38KVZ\\j.1461-0248.2004.00603.html}
}

@article{flowers.hightower_2013,
  type = {Journal Article},
  title = {A Novel Approach to Surveying Sturgeon Using Side-Scan Sonar and Occupancy Modeling},
  author = {Flowers, H. Jared and Hightower, Joseph E.},
  date = {2013},
  journaltitle = {Marine and Coastal Fisheries: Dynamics, Management, and Ecosystem Science},
  volume = {5},
  number = {1},
  pages = {211--223},
  doi = {10.1080/19425120.2013.816396},
  url = {http://pubs.er.usgs.gov/publication/70148138},
  urldate = {2022-02-18},
  abstract = {Technological advances represent opportunities to enhance and supplement traditional fisheries sampling approaches. One example with growing importance for fisheries research is hydroacoustic technologies such as side-scan sonar. Advantages of side-scan sonar over traditional techniques include the ability to sample large areas efficiently and the potential to survey fish without physical handling-important for species of conservation concern, such as endangered sturgeons. Our objectives were to design an efficient survey methodology for sampling Atlantic Sturgeon~Acipenser oxyrinchus~by using side-scan sonar and to developmethods for analyzing these data. In North Carolina and South Carolina, we surveyed six rivers thought to contain varying abundances of sturgeon by using a combination of side-scan sonar, telemetry, and video cameras (i.e., to sample jumping sturgeon). Lower reaches of each river near the saltwater-freshwater interface were surveyed on three occasions (generally successive days), and we used occupancy modeling to analyze these data.We were able to detect sturgeon in five of six rivers by using these methods. Side-scan sonar was effective in detecting sturgeon, with estimated gear-specific detection probabilities ranging from 0.2 to 0.5 and river-specific occupancy estimates (per 2-km river segment) ranging from 0.0 to 0.8. Future extensions of this occupancy modeling framework will involve the use of side-scan sonar data to assess sturgeon habitat and abundance in different river systems.},
  annotation = {IP-043165},
  file = {C:\Users\jhncsu\Zotero\storage\5CFUKVYB\Flowers and Hightower - 2013 - A novel approach to surveying sturgeon using side-.pdf}
}

@article{flowers.hightower2015,
  title = {Estimating {{Sturgeon Abundance}} in the {{Carolinas Using Side-Scan Sonar}}},
  author = {Flowers, H. Jared and Hightower, Joseph E.},
  date = {2015},
  journaltitle = {Marine and Coastal Fisheries},
  volume = {7},
  number = {1},
  pages = {1--9},
  issn = {1942-5120},
  doi = {10.1080/19425120.2014.982334},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1080/19425120.2014.982334},
  urldate = {2022-02-18},
  abstract = {Sturgeons (Acipenseridae) are one of the most threatened taxa worldwide, including species in North Carolina and South Carolina. Populations of Atlantic Sturgeon Acipenser oxyrinchus in the Carolinas have been significantly reduced from historical levels by a combination of intense fishing and habitat loss. There is a need for estimates of current abundance, to describe status, and for estimates of historical abundance in order to provide realistic recovery goals. In this study we used N-mixture and distance models with data acquired from side-scan sonar surveys to estimate abundance of sturgeon in six major sturgeon rivers in North Carolina and South Carolina. Estimated abundances of sturgeon greater than 1 m TL in the Carolina distinct population segment (DPS) were 2,031 using the count model and 1,912 via the distance model. The Pee Dee River had the highest overall abundance of any river at 1,944 (count model) or 1,823 (distance model). These estimates do not account for sturgeon less than 1 m TL or occurring in riverine reaches not surveyed or in marine waters. Comparing the two models, the N-mixture model produced similar estimates using less data than the distance model with only a slight reduction of estimated precision. Received May 3, 2014; accepted October 14, 2014},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\P8F7BAJF\\Flowers and Hightower - 2015 - Estimating Sturgeon Abundance in the Carolinas Usi.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\PR8L5IIC\\19425120.2014.html}
}

@book{gelman.etal_2013,
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  date = {2013-11-01},
  edition = {3rd edition},
  publisher = {{Chapman and Hall/CRC}},
  location = {Boca Raton London New York},
  abstract = {Winner of the 2016 De Groot Prize from the International Society for Bayesian AnalysisNow in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors―all leaders in the statistics community―introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice.New to the Third EditionFour new chapters on nonparametric modelingCoverage of weakly informative priors and boundary-avoiding priorsUpdated discussion of cross-validation and predictive information criteriaImproved convergence monitoring and effective sample size calculations for iterative simulationPresentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagationNew and revised software codeThe book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.},
  isbn = {978-1-4398-4095-5},
  langid = {english},
  pagetotal = {675}
}

@article{gelman.etal_2015,
  title = {Stan: {{A Probabilistic Programming Language}} for {{Bayesian Inference}} and {{Optimization}}},
  shorttitle = {Stan},
  author = {Gelman, Andrew and Lee, Daniel and Guo, Jiqiang},
  date = {2015},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  volume = {40},
  number = {5},
  eprint = {43966398},
  eprinttype = {jstor},
  pages = {530--543},
  publisher = {[American Educational Research Association, Sage Publications, Inc., American Statistical Association]},
  issn = {1076-9986},
  url = {https://www.jstor.org/stable/43966398},
  urldate = {2024-03-26},
  abstract = {Stan is a free and open-source C++ program that performs Bayesian inference or optimization for arbitrary user-specified models and can be called from the command line, R, Python, Matlab, or Julia and has great promise for fitting large and complex statistical models in many areas of application. We discuss Stan from users 'and developers' perspectives and illustrate with a simple but nontrivial nonlinear regression example.},
  file = {C:\Users\jhncsu\Zotero\storage\EJ3M2MQR\Gelman et al. - 2015 - Stan A Probabilistic Programming Language for Bay.pdf}
}

@article{gelman.rubin1992,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Gelman, Andrew and Rubin, Donald B.},
  date = {1992-01-01},
  journaltitle = {Statistical Science},
  volume = {7},
  pages = {457--472},
  doi = {10.1214/ss/1177011136},
  url = {https://ui.adsabs.harvard.edu/abs/1992StaSc...7..457G},
  urldate = {2022-01-31},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  annotation = {ADS Bibcode: 1992StaSc...7..457G},
  file = {C:\Users\jhncsu\Zotero\storage\J7U32DIL\Gelman and Rubin - 1992 - Inference from Iterative Simulation Using Multiple.pdf}
}

@article{hayes.brodziack1997,
  title = {Reply: {{Efficiency}} and Bias of Estimators and Sampling Designs for Determining Lengthweight Relationships of Fish},
  shorttitle = {Reply},
  author = {Hayes, D B and family=Brodziack, given=JKT, given-i=JKT},
  date = {1997-03},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {54},
  number = {3},
  pages = {744--745},
  publisher = {NRC Research Press},
  issn = {0706-652X},
  doi = {10.1139/f96-299},
  url = {https://cdnsciencepub.com/doi/abs/10.1139/f96-299},
  urldate = {2023-02-20},
  file = {C:\Users\jhncsu\Zotero\storage\9PJGRSRC\Hayes and Brodziack - 1997 - Reply Efficiency and bias of estimators and sampl.pdf}
}

@article{hayes.etal1995,
  title = {Efficiency and Bias of Estimators and Sampling Designs for Determining Length-Weight Relationships of Fish},
  author = {Hayes, Daniel B. and Brodziak, Jon K. T. and O'Gorman, Joseph B.},
  date = {1995-01},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {52},
  number = {1},
  pages = {84--92},
  publisher = {NRC Research Press},
  issn = {0706-652X},
  doi = {10.1139/f95-008},
  url = {https://cdnsciencepub.com/doi/abs/10.1139/f95-008},
  urldate = {2023-02-20},
  abstract = {The parameters of the allometric equation used to describe the length–weight relationship in fish are usually estimated by linear regression of log-transformed data. Simulation of length–weight regressions showed that for sample sizes commonly encountered in fisheries research, estimates of the intercept are biased high. In contrast with this, estimates of mean weight-at-length are biased low. As a result, different bias-correction factors are necessary to adjust for transformation bias. When the objective is to estimate the intercept of the length–weight equation, two existing methods correct for transformation bias. The appropriate bias-correction factor for mean weight-at-length, however, is exp(σ2/2) where σ2 is the residual variance of the regression. As an alternative to the log-transformation method, the properties of nonlinear least-squares regression were explored. Estimates obtained with nonlinear regression are less efficient, but are relatively robust to departures from the assumed error structure. Simulation of several sampling designs showed that greater precision without loss of accuracy is obtained as subsampling is concentrated toward the extremes of the length distribution.},
  file = {C:\Users\jhncsu\Zotero\storage\FQY2DQEJ\Hayes et al. - 1995 - Efficiency and bias of estimators and sampling des.pdf}
}

@article{hearn.etal1987,
  title = {Robust Estimation of the Natural Mortality Rate in a Completed Tagging Experiment with Variable Fishing Intensity},
  author = {Hearn, William S. and Sandland, Ronald L. and Hampton, John},
  date = {1987-01-01},
  journaltitle = {ICES Journal of Marine Science},
  shortjournal = {ICES Journal of Marine Science},
  volume = {43},
  number = {2},
  pages = {107--117},
  issn = {1054-3139},
  doi = {10.1093/icesjms/43.2.107},
  url = {https://doi.org/10.1093/icesjms/43.2.107},
  urldate = {2023-03-07},
  abstract = {A method is described for estimating the instantaneous natural mortality rate, assumed constant, in a fish population, using data from a completed tag-recapture experiment, that is, one in which the population of tagged fish is subject to fishing until no live tagged fish remain. Data from different experiments may be pooled in order to make a more accurate estimate of the natural mortality rate. Jackknife methods, utilizing an efficient computational algorithm, are used to reduce the bias of the estimate of the natural mortality rate and to provide a standard error for the estimate. The method is shown, by simulation studies, to be more robust to departures from constancy in fishing intensity than that of Gulland (1955; Biometrika, 42: 269–270), which assumes such constancy. A modification of the method which requires an additional assumption about the fishing intensity is also developed so that a preliminary estimate of the natural mortality rate can be obtained before the completion of an experiment. Southern bluefin tuna ( Thunnus maccoyii ) tag-recapture data are analysed to illustrate the use of the method in practice.},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\DFL4ADGT\\Hearn et al. - 1987 - Robust estimation of the natural mortality rate in.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\D8JY5YRY\\668429.html}
}

@article{hearn.etal2003,
  title = {Tag {{Reporting Rate Estimation}}: 3. {{Use}} of {{Planted Tags}} in {{One Component}} of a {{Multiple-Component Fishery}}},
  shorttitle = {Tag {{Reporting Rate Estimation}}},
  author = {Hearn, William S. and Hoenig, John M. and Pollock, Kenneth H. and Hepworth, Daniel A.},
  date = {2003},
  journaltitle = {North American Journal of Fisheries Management},
  volume = {23},
  number = {1},
  pages = {66--77},
  issn = {1548-8675},
  doi = {10.1577/1548-8675(2003)023<0066:TRREUO>2.0.CO;2},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1577/1548-8675%282003%29023%3C0066%3ATRREUO%3E2.0.CO%3B2},
  urldate = {2022-04-18},
  abstract = {Tag return models are used to estimate survival and tag recovery rates. With additional information on tag reporting rates, one can separate the survival rate into its fishing and natural mortality rate components. One method of estimating the tag reporting rate is to secretly plant tags in fishers' catches. However, if the fishery has more than one component, it may not be possible to plant tags in all components. Nevertheless, it is possible to estimate the reporting rates of all components in a multiple-component fishery and the fishing and natural mortality rates, if at least one component has a known reporting rate and the catches are known for each component. We simulate a variety of tag return experiments in which tags are planted in one component of a multicomponent fishery. The simulations show that this method is most effective (i.e., provides good precision of parameter estimates) when a sufficient number of tagged fish are planted into a fishery component with a high reporting rate and with a high proportion of the total catch. It is also advantageous to encourage the reporting of tags in the fishery components without planted tags. We provide a method for testing various model assumptions when it is possible to plant tags in more than one component.},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\RXRL4CA7\\Hearn et al. - 2003 - Tag Reporting Rate Estimation 3. Use of Planted T.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\P7YLSFHD\\1548-8675(2003)0230066TRREUO2.0.html}
}

@article{hewitt.etal2010,
  title = {Improving Inferences from Fisheries Capture-Recapture Studies through Remote Detection of PIT Tags},
  author = {Hewitt, David A. and Janney, Eric C. and Hayes, Brian S. and Shively, Rip S.},
  date = {2010},
  journaltitle = {Fisheries},
  volume = {35},
  number = {5},
  pages = {217--231},
  issn = {1548-8446},
  doi = {10.1577/1548-8446-35.5.217},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1577/1548-8446-35.5.217},
  urldate = {2022-03-23},
  abstract = {Models for capture-recapture data are commonly used in analyses of the dynamics of fish and wildlife populations, especially for estimating vital parameters such as survival. Capture-recapture methods provide more reliable inferences than other methods commonly used in fisheries studies. However, for rare or elusive fish species, parameter estimation is often hampered by small probabilities of re-encountering tagged fish when encounters are obtained through traditional sampling methods. We present a case study that demonstrates how remote antennas for passive integrated transponder (PIT) tags can increase encounter probabilities and the precision of survival estimates from capture-recapture models. Between 1999 and 2007, trammel nets were used to capture and tag over 8,400 endangered adult Lost River suckers (Deltistes luxatus) during the spawning season in Upper Klamath Lake, Oregon. Despite intensive sampling at relatively discrete spawning areas, encounter probabilities from Cormack-Jolly-Seber models were consistently low ({$<$} 0.2) and the precision of apparent annual survival estimates was poor. Beginning in 2005, remote PIT tag antennas were deployed at known spawning locations to increase the probability of re-encountering tagged fish. We compare results based only on physical recaptures with results based on both physical recaptures and remote detections to demonstrate the substantial improvement in estimates of encounter probabilities (approaching 100\%) and apparent annual survival provided by the remote detections. The richer encounter histories provided robust inferences about the dynamics of annual survival and have made it possible to explore more realistic models and hypotheses about factors affecting the conservation and recovery of this endangered species. Recent advances in technology related to PIT tags have paved the way for creative implementation of large-scale tagging studies in systems where they were previously considered impracticable.},
  langid = {spanish},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\V7EGX5PT\\Hewitt et al. - 2010 - Improving Inferences from Fisheries Capture-Recapt.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\PCL7U2NH\\1548-8446-35.5.html}
}

@article{hightower.etal2001,
  title = {Use of {{Telemetry Methods}} to {{Estimate Natural}} and {{Fishing Mortality}} of {{Striped Bass}} in {{Lake Gaston}}, {{North Carolina}}},
  author = {Hightower, Joseph E. and Jackson, James R. and Pollock, Kenneth H.},
  date = {2001-07-01},
  journaltitle = {Transactions of the American Fisheries Society},
  volume = {130},
  number = {4},
  pages = {557--567},
  publisher = {Taylor \& Francis},
  issn = {0002-8487},
  doi = {10.1577/1548-8659(2001)130<0557:UOTMTE>2.0.CO;2},
  url = {https://doi.org/10.1577/1548-8659(2001)130<0557:UOTMTE>2.0.CO;2},
  urldate = {2022-03-22},
  abstract = {Natural mortality can substantially affect fish population dynamics, but the rate is difficult to estimate because natural deaths are rarely observed and it is difficult to separate the effects of natural and fishing mortality on abundance. We developed a new telemetry approach for estimating natural and fishing mortality rates and applied it to the population of striped bass Morone saxatilis in Lake Gaston, North Carolina and Virginia. Our analyses were based on a sample size of 51 telemetered striped bass that were known to be alive and in Lake Gaston at least 1 month after capture and surgery. Relocations of live fish and fish that died of natural causes were used to estimate natural and fishing mortality rates and the probability of relocating telemetered fish. Fishing mortality rates varied seasonally, but few natural deaths were observed, so the best model incorporated a constant annual instantaneous natural mortality rate (M; ±SE) of 0.14 ± 0.02. With the uncertainty in model selection accounted for, the average annual M was 0.16 ± 0.04 for 1997 and 0.12 ± 0.04 for 1998. Estimated annual fishing mortality rates (F) were 0.74 ± 0.13 for 1997 and 0.34 ± 0.18 for 1998. This telemetry approach for estimating mortality rates does not rely on angler reporting of tagged fish. The relative standard errors for M (24–33\%) were comparable to those obtained from traditional tagging methods with large sample sizes. This approach is most applicable in closed systems, where fishing mortality estimates are not biased by emigration. A high relocation probability is critical to reliably establishing seasonal changes in mortality.},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\ZG554KGI\\Hightower et al. - 2001 - Use of Telemetry Methods to Estimate Natural and F.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\SUCIX5ZJ\\1548-8659(2001)1300557UOTMTE2.0.html}
}

@article{hightower.etal2015,
  title = {Estimated {{Survival}} of {{Subadult}} and {{Adult Atlantic Sturgeon}} in {{Four River Basins}} in the {{Southeastern United States}}},
  author = {Hightower, Joseph E. and Loeffler, Michael and Post, William C. and Peterson, Douglas L.},
  date = {2015},
  journaltitle = {Marine and Coastal Fisheries},
  volume = {7},
  number = {1},
  pages = {514--522},
  issn = {1942-5120},
  doi = {10.1080/19425120.2015.1088491},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1080/19425120.2015.1088491},
  urldate = {2022-03-23},
  abstract = {Prompted by concerns about the status of Atlantic Sturgeon Acipenser oxyrinchus oxyrinchus, in 2012 the National Oceanic and Atmospheric Administration listed one distinct population segment (DPS) as threatened (Gulf of Maine) and listed the remaining four DPSs as endangered (New York Bight, Chesapeake Bay, Carolina, and South Atlantic). To provide information for recovery planning, we estimated the survival of subadult and adult Atlantic Sturgeon in two river basins within the Carolina DPS (Roanoke and Cape Fear rivers, North Carolina) and two basins within the South Atlantic DPS (Ashepoo–Combahee–Edisto rivers [ACE], South Carolina; Altamaha River, Georgia). Estimated detection probability varied strongly by season but was similar among river basins, likely reflecting a winter migration into marine waters with minimal receiver coverage. Apparent monthly survival was very high and precisely estimated for the Roanoke River (0.985; 95\% credible interval [CI] = 0.970–0.995), Cape Fear River (0.979; 95\% CI = 0.971–0.986), ACE (0.989; 95\% CI = 0.979–0.993), and Altamaha River (0.985; 95\% CI = 0.973–0.994) basins. A pooled estimate for 87 adults from all four basins was 0.988 (95\% CI = 0.982–0.992). The monthly rates implied annual apparent survival rates of 0.839 (Roanoke River basin), 0.778 (Cape Fear River basin), 0.871 (ACE basin), and 0.842 (Altamaha River basin); the pooled estimate for adults was 0.860. Our estimated survival rates were similar to other recent estimates for Atlantic Sturgeon but lower than recent estimates for several populations of Gulf Sturgeon A. oxyrinchus desotoi. Recovery of Atlantic Sturgeon in these southeastern rivers will occur more quickly if survival can be increased to a level that is consistent with published estimates of true natural mortality (0.03–0.07; annual survival ≥ 0.93). Received March 18, 2015; accepted August 26, 2015},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\M8DF3TDL\\Hightower et al. - 2015 - Estimated Survival of Subadult and Adult Atlantic .pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\WYSS3KFZ\\19425120.2015.html}
}

@article{hightower.grossman_1985,
  title = {Comparison of {{Constant Effort Harvest Policies}} for {{Fish Stocks}} with {{Variable Recruitment}}},
  author = {Hightower, Joseph E. and Grossman, Gary D.},
  date = {1985-05},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {42},
  number = {5},
  pages = {982--988},
  publisher = {NRC Research Press},
  issn = {0706-652X},
  doi = {10.1139/f85-123},
  url = {https://cdnsciencepub.com/doi/abs/10.1139/f85-123},
  urldate = {2023-04-12},
  abstract = {Environmental variability may have a substantial influence on marine fish stocks, primarily by affecting survival to the time of recruitment. Simulation studies at low, intermediate, and high levels of variability in recruitment were used to compare alternative constant effort policies for anchovy (Engraulis capensis), Atlantic menhaden (Brevoortia tyrannus), and Pacific ocean perch (Sebastes alutus) fisheries. These policies were either to maintain effort at the level producing maximum sustainable yield (fMSY), or to permit levels of effort 25–100\% greater than fMSY. An increase in effort of 25\% above fMSY typically did not reduce annual yield significantly; however, a significant reduction in yield was apparent in all cases when effort increased by 75–100\%. When recruitment is highly variable, comparable yields may be obtained at several levels of fishing effort. In such cases, environmental variability provides the fishery manager with considerable flexibility to enhance social or economic benefits without decreasing yields significantly.},
  file = {C:\Users\jhncsu\Zotero\storage\DLRKCPE9\Hightower and Grossman - 1985 - Comparison of Constant Effort Harvest Policies for.pdf}
}

@article{hightower.harris2017,
  title = {Estimating {{Fish Mortality Rates Using Telemetry}} and {{Multistate Models}}},
  author = {Hightower, Joseph E. and Harris, Julianne E.},
  date = {2017},
  journaltitle = {Fisheries},
  volume = {42},
  number = {4},
  pages = {210--219},
  issn = {1548-8446},
  doi = {10.1080/03632415.2017.1276347},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1080/03632415.2017.1276347},
  urldate = {2022-03-23},
  abstract = {We simulated and evaluated multistate capture–recapture models to estimate mortality rates using telemetry data. Four field designs were considered: (A) fixed receivers to estimate total instantaneous mortality (Z), (B) manual searches to estimate instantaneous fishing (F) and natural (M) mortality, (C) fixed receivers combined with external high-reward tags to estimate F and M, and (D) manual searches combined with external high-reward tags to estimate M and fishing mortality rates associated with harvest (Fh) and catch-and-release death (Fcr) as well as the probability of death due to catch and release (α). Estimates generally appeared to be unbiased for a simulated study with five periods and releases of telemetered fish at the start of periods 1–4. Compared to estimating Z, larger sample sizes are needed to achieve reliable estimates of component rates (F and M). Estimates of component rates were more precise when that source of mortality was directly observed (M in design B, F in design C). The field design using fixed receivers and high-reward tags should be especially useful in practice, because manual searches are not required to estimate F and M. Multistate models are useful for clarifying the connection between field observations and ecological processes. Reliable estimates of mortality rates, coupled with information on behavior, habitat use, and movement, make telemetry a highly valuable tool for improving fisheries management and stock assessment.},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\L3A7QBCX\\Hightower and Harris - 2017 - Estimating Fish Mortality Rates Using Telemetry an.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\JKNIKGII\\03632415.2017.html}
}

@article{hightower2015,
  title = {Estimated {{Survival}} of {{Subadult}} and {{Adult Atlantic Sturgeon}} in {{Four River Basins}} in the {{Southeastern United States}}},
  author = {Hightower, Joseph E.},
  date = {2015-01},
  journaltitle = {Marine and Coastal Fisheries: Dynamics, Management, and Ecosystem Science},
  shortjournal = {fidm},
  volume = {7},
  number = {7},
  pages = {514--522},
  publisher = {American Fisheries Society},
  issn = {1942-5120},
  doi = {10.1080/19425120.2015.1088491},
  url = {http://bioone.org/journals/marine-and-coastal-fisheries/volume-7/issue-7/19425120.2015.1088491/Estimated-Survival-of-Subadult-and-Adult-Atlantic-Sturgeon-in-Four/10.1080/19425120.2015.1088491.full},
  urldate = {2022-03-23},
  abstract = {Prompted by concerns about the status of Atlantic Sturgeon Acipenser oxyrinchus oxyrinchus, in 2012 the National Oceanic and Atmospheric Administration listed one distinct population segment (DPS) as threatened (Gulf of Maine) and listed the remaining four DPSs as endangered (New York Bight, Chesapeake Bay, Carolina, and South Atlantic). To provide information for recovery planning, we estimated the survival of subadult and adult Atlantic Sturgeon in two river basins within the Carolina DPS (Roanoke and Cape Fear rivers, North Carolina) and two basins within the South Atlantic DPS (Ashepoo—Combahee—Edisto rivers [ACE], South Carolina; Altamaha River, Georgia). Estimated detection probability varied strongly by season but was similar among river basins, likely reflecting a winter migration into marine waters with minimal receiver coverage. Apparent monthly survival was very high and precisely estimated for the Roanoke River (0.985; 95\% credible interval [CI] = 0.970-0.995), Cape Fear River (0.979; 95\% CI = 0.971-0.986), ACE (0.989; 95\% CI = 0.979-0.993), and Altamaha River (0.985; 95\% CI = 0.973-0.994) basins. A pooled estimate for 87 adults from all four basins was 0.988 (95\% CI = 0.982-0.992). The monthly rates implied annual apparent survival rates of 0.839 (Roanoke River basin), 0.778 (Cape Fear River basin), 0.871 (ACE basin), and 0.842 (Altamaha River basin); the pooled estimate for adults was 0.860. Our estimated survival rates were similar to other recent estimates for Atlantic Sturgeon but lower than recent estimates for several populations of Gulf Sturgeon A. oxyrinchus desotoi. Recovery of Atlantic Sturgeon in these southeastern rivers will occur more quickly if survival can be increased to a level that is consistent with published estimates of true natural mortality (0.03–0.07; annual survival ≥ 0.93).},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\8C52GRDX\\Hightower - 2015 - Estimated Survival of Subadult and Adult Atlantic .pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\2X2M8SL2\\19425120.2015.1088491.html}
}

@book{hilborn.walters_1992,
  title = {Quantitative {{Fisheries Stock Assessment}}},
  author = {Hilborn, Ray and Walters, Carl J.},
  date = {1992},
  publisher = {Springer US},
  location = {Boston, MA},
  doi = {10.1007/978-1-4615-3598-0},
  url = {http://link.springer.com/10.1007/978-1-4615-3598-0},
  urldate = {2023-04-09},
  isbn = {978-1-4020-1845-9 978-1-4615-3598-0},
  langid = {english},
  keywords = {biomass,fish,fisheries management,growth}
}

@article{hooten.hobbs2015,
  title = {A Guide to {{Bayesian}} Model Selection for Ecologists},
  author = {Hooten, M. B. and Hobbs, N. T.},
  date = {2015},
  journaltitle = {Ecological Monographs},
  volume = {85},
  number = {1},
  pages = {3--28},
  issn = {1557-7015},
  doi = {10.1890/14-0661.1},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1890/14-0661.1},
  urldate = {2022-10-04},
  abstract = {The steady upward trend in the use of model selection and Bayesian methods in ecological research has made it clear that both approaches to inference are important for modern analysis of models and data. However, in teaching Bayesian methods and in working with our research colleagues, we have noticed a general dissatisfaction with the available literature on Bayesian model selection and multimodel inference. Students and researchers new to Bayesian methods quickly find that the published advice on model selection is often preferential in its treatment of options for analysis, frequently advocating one particular method above others. The recent appearance of many articles and textbooks on Bayesian modeling has provided welcome background on relevant approaches to model selection in the Bayesian framework, but most of these are either very narrowly focused in scope or inaccessible to ecologists. Moreover, the methodological details of Bayesian model selection approaches are spread thinly throughout the literature, appearing in journals from many different fields. Our aim with this guide is to condense the large body of literature on Bayesian approaches to model selection and multimodel inference and present it specifically for quantitative ecologists as neutrally as possible. We also bring to light a few important and fundamental concepts relating directly to model selection that seem to have gone unnoticed in the ecological literature. Throughout, we provide only a minimal discussion of philosophy, preferring instead to examine the breadth of approaches as well as their practical advantages and disadvantages. This guide serves as a reference for ecologists using Bayesian methods, so that they can better understand their options and can make an informed choice that is best aligned with their goals for inference.},
  langid = {english},
  keywords = {Akaike information criterion,Bayes factors,cross-validation,deviance information criterion,model averaging,multi-model inference,regularization,shrinkage},
  file = {C:\Users\jhncsu\Zotero\storage\GI6S4GMV\14-0661.html}
}

@article{jiang.etal2007,
  title = {Tag {{Return Models Allowing}} for {{Harvest}} and {{Catch}} and {{Release}}: {{Evidence}} of {{Environmental}} and {{Management Impacts}} on {{Striped Bass Fishing}} and {{Natural Mortality Rates}}},
  shorttitle = {Tag {{Return Models Allowing}} for {{Harvest}} and {{Catch}} and {{Release}}},
  author = {Jiang, Honghua and Pollock, Kenneth H. and Brownie, Cavell and Hoenig, John M. and Latour, Robert J. and Wells, Brian K. and Hightower, Joseph E.},
  date = {2007},
  journaltitle = {North American Journal of Fisheries Management},
  volume = {27},
  number = {2},
  pages = {387--396},
  issn = {1548-8675},
  doi = {10.1577/M06-089.1},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1577/M06-089.1},
  urldate = {2022-04-10},
  abstract = {Catch-and-release fisheries have become very important in the management of overexploited recreational fish stocks. Tag return studies, where the tag is removed regardless of fish disposition, have been used to assess the effectiveness of restoration efforts for these fisheries. We extend the instantaneous rate formulation of tag return models to allow for catch and release as well as harvest. The key point of our methods is that, given an estimate of the tag reporting rate, the fishing mortality rate (F) is separated into two components: the mortality on harvested fish and the “mortality” on tags (because the tags are removed) of fish released alive. The total fishing mortality rate for untagged fish is the sum of the Fs due to harvest and hooking mortality suffered by fish released alive. Natural mortality rates can also be estimated. Both age-independent models and age-dependent models are constructed, and the age-dependent models are illustrated by application to data from a study of striped bass Morone saxatilis in Chesapeake Bay from 1991 to 2003 by the Maryland Department of Natural Resources. By fitting models of the natural mortality rate with limited age and year dependence, we demonstrate an overall decrease in natural mortality rates as fish age and provide evidence of an increase in natural mortality beginning in the late 1990s, when an outbreak of the disease mycobacteriosis is thought to have begun. Our results indicate that fishing mortality is age dependent; selectivity increases up to age 6, when fish appear to be fully recruited to the fishery. There is also evidence of an increase in fishing mortality since 1995, when regulations were relaxed.},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\KFHIH5SB\\Jiang et al. - 2007 - Tag Return Models Allowing for Harvest and Catch a.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\VAXK2UGQ\\M06-089.html}
}

@book{kéry_2010,
  title = {Introduction to {{WinBUGS}} for {{Ecologists}}: {{Bayesian}} Approach to Regression, {{ANOVA}}, Mixed Models and Related Analyses},
  shorttitle = {Introduction to {{WinBUGS}} for {{Ecologists}}},
  author = {Kéry, Marc},
  date = {2010-07-01},
  edition = {1st edition},
  publisher = {Academic Press},
  location = {Amsterdam ; Boston},
  isbn = {978-0-12-378605-0},
  langid = {english},
  pagetotal = {320}
}

@book{kéry.schaub_2011,
  title = {Bayesian {{Population Analysis}} Using {{WinBUGS}}: {{A Hierarchical Perspective}}},
  shorttitle = {Bayesian {{Population Analysis}} Using {{WinBUGS}}},
  author = {Kéry, Marc and Schaub, Michael},
  date = {2011-10-12},
  edition = {1st edition},
  publisher = {Academic Press},
  location = {Boston},
  isbn = {978-0-12-387020-9},
  langid = {english},
  pagetotal = {554}
}

@book{law.kelton_1982,
  title = {Simulation {{Modeling}} and {{Analysis}}},
  author = {Law, Averill M. and Kelton, W. David},
  date = {1982},
  eprint = {xOBQAAAAMAAJ},
  eprinttype = {googlebooks},
  publisher = {McGraw-Hill},
  isbn = {978-0-07-036696-1},
  langid = {english},
  pagetotal = {424}
}

@book{link.barker_2009,
  title = {Bayesian {{Inference}}: {{With Ecological Applications}}},
  shorttitle = {Bayesian {{Inference}}},
  author = {Link, William A. and Barker, Richard J.},
  date = {2009-08-18},
  edition = {1st edition},
  publisher = {Academic Press},
  location = {Amsterdam Boston London},
  abstract = {This text is written to provide a mathematically sound but accessible and engaging introduction to Bayesian inference specifically for environmental scientists, ecologists and wildlife biologists. It emphasizes the power and usefulness of Bayesian methods in an ecological context.The advent of fast personal computers and easily available software has~simplified the use of~Bayesian and hierarchical~models . One obstacle remains for ecologists and wildlife biologists, namely the near absence of Bayesian texts written specifically for them. The book includes many relevant examples, is supported by software and examples on a companion website and will become an essential grounding in this approach~for~students and research ecologists.Engagingly written text specifically designed to demystify a complex subjectExamples drawn from ecology and wildlife researchAn essential grounding for graduate and research ecologists in the increasingly prevalent Bayesian approach to inferenceCompanion website with analytical software and examplesLeading authors with world-class reputations in ecology and biostatistics},
  isbn = {978-0-12-374854-6},
  langid = {english},
  pagetotal = {354}
}

@online{link.barker_2010,
  title = {Bayesian Inference : With Ecological Applications - {{NC State University Libraries Catalog}}},
  author = {Link, William A. and Barker, Richard J.},
  date = {2010},
  url = {https://catalog.lib.ncsu.edu/catalog/NCSU5404799},
  urldate = {2023-04-30}
}

@article{link.eaton2012,
  title = {On Thinning of Chains in {{MCMC}}},
  author = {Link, William A. and Eaton, Mitchell J.},
  date = {2012},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {3},
  number = {1},
  pages = {112--115},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210X.2011.00131.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210X.2011.00131.x},
  urldate = {2022-01-28},
  abstract = {1. Markov chain Monte Carlo (MCMC) is a simulation technique that has revolutionised the analysis of ecological data, allowing the fitting of complex models in a Bayesian framework. Since 2001, there have been nearly 200 papers using MCMC in publications of the Ecological Society of America and the British Ecological Society, including more than 75 in the journal Ecology and 35 in the Journal of Applied Ecology. 2. We have noted that many authors routinely ‘thin’ their simulations, discarding all but every kth sampled value; of the studies we surveyed with details on MCMC implementation, 40\% reported thinning. 3. Thinning is often unnecessary and always inefficient, reducing the precision with which features of the Markov chain are summarised. The inefficiency of thinning MCMC output has been known since the early 1990’s, long before MCMC appeared in ecological publications. 4. We discuss the background and prevalence of thinning, illustrate its consequences, discuss circumstances when it might be regarded as a reasonable option and recommend against routine thinning of chains unless necessitated by computer memory limitations.},
  langid = {english},
  keywords = {Markov chain Monte Carlo,thinning,WinBUGS},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\4D9HKKH8\\Link and Eaton - 2012 - On thinning of chains in MCMC.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\YWWRNI85\\j.2041-210X.2011.00131.html}
}

@article{lorenzen1996,
  title = {The Relationship between Body Weight and Natural Mortality in Juvenile and Adult Fish: A Comparison of Natural Ecosystems and Aquaculture},
  shorttitle = {The Relationship between Body Weight and Natural Mortality in Juvenile and Adult Fish},
  author = {Lorenzen, K.},
  date = {1996},
  journaltitle = {Journal of Fish Biology},
  volume = {49},
  number = {4},
  pages = {627--642},
  issn = {1095-8649},
  doi = {10.1111/j.1095-8649.1996.tb00060.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1095-8649.1996.tb00060.x},
  urldate = {2022-02-23},
  abstract = {The relationship between body weight and natural mortality in juvenile and adult fish was analysed for different aquatic ecosystems: lakes, rivers, the ocean, and pond, cage and tank aquaculture systems. Mortality was modelled as a power function of weight, and the parameters b (exponent) and Mu (mortality at the unit weight of 1 g) estimated for fish in the six ecosystems, as well as within selected populations, species and families. At the ecosystem level, no significant differences in parameters were found between lakes, rivers and the ocean and a joint mortality-weight relationship for all natural ecosystems was estimated with parameters b=−0.288 (90\% CL[−0.315, −0.261]) and Mu=3.00 (90\% CL[2.70, 3.30]) year−1. Among the culture systems, mortality-weight relationships in ponds and cages were not significantly different and a joint relationship was estimated. The weight exponents of mortality in ponds/cages and tanks were very similar at about b=−0.43, and significantly more negative than in natural ecosystems. Mortalities at unit weight were significantly lower in tanks (0.91 year−1) than in ponds/cages (2.24 year−1), and both were significantly lower than in natural ecosystems. No systematic differences were found between the mortality-weight relationships determined for individual populations, species or families, and fish in the respective ecosystems. It is hypothesized that aquaculture mortality-weight relationships indicate the allometric scaling of non-predation mortality, which is therefore more strongly size dependent than predation mortality. If non predation mortality in natural ecosystems shows a similar scaling with body weight, then the allometric exponent of predation mortality must be less negative than that observed for total natural mortality. Implications of the established mortality-weight relationships for aquaculture and culture-based fisheries are discussed.},
  langid = {english},
  keywords = {allometry,aquaculture,body weight,ecosystem,mortality,predation},
  file = {C:\Users\jhncsu\Zotero\storage\F9LP7C45\j.1095-8649.1996.tb00060.html}
}

@article{lunn.etal2000,
  title = {{{WinBUGS}} - {{A Bayesian}} Modelling Framework: {{Concepts}}, Structure, and Extensibility},
  shorttitle = {{{WinBUGS}} - {{A Bayesian}} Modelling Framework},
  author = {Lunn, David J. and Thomas, Andrew and Best, Nicky and Spiegelhalter, David},
  date = {2000-10-01},
  journaltitle = {Statistics and Computing},
  shortjournal = {Statistics and Computing},
  volume = {10},
  number = {4},
  pages = {325--337},
  issn = {1573-1375},
  doi = {10.1023/A:1008929526011},
  url = {https://doi.org/10.1023/A:1008929526011},
  urldate = {2022-11-20},
  abstract = {WinBUGS is a fully extensible modular framework for constructing and analysing Bayesian full probability models. Models may be specified either textually via the BUGS language or pictorially using a graphical interface called DoodleBUGS. WinBUGS processes the model specification and constructs an object-oriented representation of the model. The software offers a user-interface, based on dialogue boxes and menu commands, through which the model may then be analysed using Markov chain Monte Carlo techniques. In this paper we discuss how and why various modern computing concepts, such as object-orientation and run-time linking, feature in the software's design. We also discuss how the framework may be extended. It is possible to write specific applications that form an apparently seamless interface with WinBUGS for users with specialized requirements. It is also possible to interface with WinBUGS at a lower level by incorporating new object types that may be used by WinBUGS without knowledge of the modules in which they are implemented. Neither of these types of extension require access to, or even recompilation of, the WinBUGS source-code.},
  langid = {english},
  keywords = {BUGS,directed acyclic graphs,Markov chain Monte Carlo,object-orientation,run-time linking,type extension,WinBUGS}
}

@article{lunn.etal2000a,
  title = {{{WinBUGS}}—{{A Bayesian Modelling Framework}}:{{Concepts}}, {{Structure}}, and {{Extensibility}}},
  author = {Lunn, D.and Thomas, A. and Best, N. and Spiegelhalter, D.},
  date = {2000},
  journaltitle = {Statistics and Computing},
  volume = {10},
  pages = {325--337},
  doi = {10.1023/A:1008929526011}
}

@article{lunn.etal2009,
  title = {The {{BUGS}} Project: {{Evolution}}, Critique and Future Directions},
  shorttitle = {The {{BUGS}} Project},
  author = {Lunn, David and Spiegelhalter, David and Thomas, Andrew and Best, Nicky},
  date = {2009},
  journaltitle = {Statistics in Medicine},
  volume = {28},
  number = {25},
  pages = {3049--3067},
  issn = {1097-0258},
  doi = {10.1002/sim.3680},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3680},
  urldate = {2022-01-27},
  abstract = {BUGS is a software package for Bayesian inference using Gibbs sampling. The software has been instrumental in raising awareness of Bayesian modelling among both academic and commercial communities internationally, and has enjoyed considerable success over its 20-year life span. Despite this, the software has a number of shortcomings and a principal aim of this paper is to provide a balanced critical appraisal, in particular highlighting how various ideas have led to unprecedented flexibility while at the same time producing negative side effects. We also present a historical overview of the BUGS project and some future perspectives. Copyright © 2009 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {Bayesian modelling,BUGS,graphical models,OpenBUGS,WinBUGS},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\HRRS6W3N\\Lunn et al. - 2009 - The BUGS project Evolution, critique and future d.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\H4S4HQZE\\sim.html}
}

@book{lunn.etal2012,
  title = {The {{BUGS Book}}: {{A Practical Introduction}} to {{Bayesian Analysis}}},
  shorttitle = {The {{BUGS Book}}},
  author = {Lunn, David and Jackson, Chris and Best, Nicky and Thomas, Andrew and Spiegelhalter, David},
  date = {2012-10-02},
  edition = {1st edition},
  publisher = {{Chapman and Hall/CRC}},
  langid = {english},
  pagetotal = {381}
}

@article{mantyniemi.etal2005,
  title = {Bayesian Removal Estimation of a Population Size under Unequal Catchability},
  author = {Mäntyniemi, Samu and Romakkaniemi, Atso and Arjas, Elja},
  date = {2005-02-01},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Canadian Journal of Fisheries and Aquatic Sciences},
  volume = {62},
  pages = {291--300},
  doi = {10.1139/f04-195},
  abstract = {We introduce a Bayesian probability model for the estimation of the size of an animal population from removal data. The model is based on the assumption that in the removal sampling, catchability may vary between individuals, which appears to be necessary for a realistic description of many biological populations. Heterogeneous catchability among individuals leads to a situation where the mean catchability in the population gradually decreases as the number of removals increases. Under this assumption, the model can be fitted to any removal data, i.e., there are no limitations regarding the total catch, the number of removals, or the decline of the catch. Using a published data set from removal experiments of a known population size, the model is shown to be able to estimate the population size appropriately in all cases considered. It is also shown that regardless of the statistical approach, a model that assumes equal catchability of individuals generally leads to an underestimation of the population. The example indicates that if there is only vague prior information about the variation of catchability among individuals, a very high number of successive removals may be needed to correctly estimate the population size.},
  file = {C:\Users\jhncsu\Zotero\storage\TNEDV27M\Mäntyniemi et al. - 2005 - Bayesian removal estimation of a population size u.pdf}
}

@book{mccarthy2007,
  title = {Bayesian {{Methods}} for {{Ecology}}},
  author = {McCarthy, Michael A.},
  date = {2007-05-14},
  edition = {1st edition},
  publisher = {Cambridge University Press},
  location = {Cambridge, UK ; New York},
  isbn = {978-0-521-61559-4},
  langid = {english},
  pagetotal = {312}
}

@article{millar.meyer2000,
  title = {Bayesian State-Space Modeling of Age-Structured Data: Fitting a Model Is Just the Beginning},
  shorttitle = {Bayesian State-Space Modeling of Age-Structured Data},
  author = {Millar, Russell B and Meyer, Renate},
  date = {2000-01},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {57},
  number = {1},
  pages = {43--50},
  publisher = {NRC Research Press},
  issn = {0706-652X},
  doi = {10.1139/f99-169},
  url = {https://cdnsciencepub.com/doi/10.1139/f99-169},
  urldate = {2022-12-27},
  abstract = {Explicit modeling of process variability in the dynamics of fisheries is motivated by a desire to incorporate more realism into stock assessment models, and much recent research effort has been devoted to the computational features of fitting state-space models for this purpose. Here, we extend the Bayesian application of nonlinear state-space modeling to sequential population analysis of age-structured data using a model formulation that allows for unreported catches and incidental fishing mortality. It is shown that, once a familiarity with the general-purpose Bayesian software BUGS is acquired, implementing a state-space model is a relatively simple task. Indeed, this application requires just 18 lines of code in its entirety and does not require the programmer to know the formulae for any prior density functions or likelihoods. Consequently, we suggest that this methodology may permit the implementation phase of nonlinear state-space modeling to be relegated, thereby allowing more effort to be devoted to the challenging issues of model checking, selection/averaging, sensitivity, and prior specification.}
}

@article{monnahan.etal_2017,
  title = {Faster Estimation of {{Bayesian}} Models in Ecology Using {{Hamiltonian Monte Carlo}}},
  author = {Monnahan, Cole C. and Thorson, James T. and Branch, Trevor A.},
  date = {2017},
  journaltitle = {Methods in Ecology and Evolution},
  volume = {8},
  number = {3},
  pages = {339--348},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12681},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12681},
  urldate = {2024-03-26},
  abstract = {Bayesian inference is a powerful tool to better understand ecological processes across varied subfields in ecology, and is often implemented in generic and flexible software packages such as the widely used BUGS family (BUGS, WinBUGS, OpenBUGS and JAGS). However, some models have prohibitively long run times when implemented in BUGS. A relatively new software platform called Stan uses Hamiltonian Monte Carlo (HMC), a family of Markov chain Monte Carlo (MCMC) algorithms which promise improved efficiency and faster inference relative to those used by BUGS. Stan is gaining traction in many fields as an alternative to BUGS, but adoption has been slow in ecology, likely due in part to the complex nature of HMC. Here, we provide an intuitive illustration of the principles of HMC on a set of simple models. We then compared the relative efficiency of BUGS and Stan using population ecology models that vary in size and complexity. For hierarchical models, we also investigated the effect of an alternative parameterization of random effects, known as non-centering. For small, simple models there is little practical difference between the two platforms, but Stan outperforms BUGS as model size and complexity grows. Stan also performs well for hierarchical models, but is more sensitive to model parameterization than BUGS. Stan may also be more robust to biased inference caused by pathologies, because it produces diagnostic warnings where BUGS provides none. Disadvantages of Stan include an inability to use discrete parameters, more complex diagnostics and a greater requirement for hands-on tuning. Given these results, Stan is a valuable tool for many ecologists utilizing Bayesian inference, particularly for problems where BUGS is prohibitively slow. As such, Stan can extend the boundaries of feasible models for applied problems, leading to better understanding of ecological processes. Fields that would likely benefit include estimation of individual and population growth rates, meta-analyses and cross-system comparisons and spatiotemporal models.},
  langid = {english},
  keywords = {Bayesian inference,hierarchical modelling,Markov chain Monte Carlo,no-U-turn sampler,Stan},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\9R3JENC9\\Monnahan et al. - 2017 - Faster estimation of Bayesian models in ecology us.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\7ZLVQN2T\\2041-210X.html}
}

@book{ogle_2018,
  title = {Introductory {{Fisheries Analyses}} with {{R}}},
  author = {Ogle, by Derek H.},
  date = {2018},
  series = {Chapman \& {{Hall}}/{{CRC The R Series}}},
  edition = {First edition.},
  publisher = {{Boca Raton, FL : Chapman and Hall/CRC, [2018].}},
  url = {https://catalog.lib.ncsu.edu/catalog/NCSU4637798},
  isbn = {978-1-315-37198-6 978-1-4822-3520-3},
  file = {C:\Users\jhncsu\Zotero\storage\3RWU6ABN\NCSU4637798.html}
}

@article{plummer2003,
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  author = {Plummer, M.},
  date = {2003},
  journaltitle = {Proceedings of the 3rd International Workshop on Distributed Statistical Computing},
  doi = {10.1023/A:1008929526011},
  url = {https://www.r-project.org/conferences/DSC-2003/Proceedings/Plummer.pdf}
}

@article{plummerJAGSProgramAnalysis2003,
  title = {{{JAGS}}: {{A Program}} for {{Analysis}} of {{Bayesian Graphical Models Using Gibbs Sampling}}},
  author = {Plummer, Martyn},
  date = {2003},
  pages = {10},
  abstract = {JAGS is a program for Bayesian Graphical modelling which aims for compatibility with classic BUGS. The program could eventually be developed as an R package. This article explains the motivations for this program, briefly describes the architecture and then discusses some ideas for a vectorized form of the BUGS language.},
  langid = {english},
  keywords = {Plummer2003},
  file = {C:\Users\jhncsu\Zotero\storage\7IIEVBAN\Plummer - 2003 - JAGS A Program for Analysis of Bayesian Graphical.pdf}
}

@article{pollock.etal_2001,
  title = {Tag {{Reporting Rate Estimation}}: 1. {{An Evaluation}} of the {{High-Reward Tagging Method}}},
  shorttitle = {Tag {{Reporting Rate Estimation}}},
  author = {Pollock, Kenneth H. and Hoenig, John M. and Hearn, William S. and Calingaert, Brian},
  date = {2001},
  journaltitle = {North American Journal of Fisheries Management},
  volume = {21},
  number = {3},
  pages = {521--532},
  issn = {1548-8675},
  doi = {10.1577/1548-8675(2001)021<0521:TRREAE>2.0.CO;2},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1577/1548-8675%282001%29021%3C0521%3ATRREAE%3E2.0.CO%3B2},
  urldate = {2024-02-10},
  abstract = {Tag-return models can be used to estimate survival rates and tag recovery rates. The additional knowledge of an estimated tag reporting rate allows one to separate total mortality into fishing and natural mortality rates. This paper examines the use of high-reward tags in tagging studies. We find that many of the problems encountered in tagging studies can be avoided if tagged animals are released in small batches in as many locations as possible rather than in large batches at a few locations. Often, the use of substantial monetary rewards for the return of standard tags may be justified as cost effective because of the higher tag return rates they induce. The high-reward tagging method is an important method for estimating the tag reporting rate for standard tags. For this method it is assumed that high-reward tags are reported 100\% of the time. This assumption is investigated. Other assumptions of the method are also considered, and particular attention is paid to whether the reporting rate of standard tags may change when a high-reward tagging study is initiated. This is of particular concern in cases in which standard tags are used for all study years and high-reward tags are only used in some subset of the study years. If the natural mortality rate is assumed to be constant over all years, then fishing and natural mortality together with two tag reporting rates can be estimated. Simulation analysis shows that fishing mortality estimates are unbiased in this case but have significantly higher coefficients of variation in the years without high-reward tags. Natural mortality estimates are unbiased and reasonably efficient, but this is crucially dependent on the assumption that natural mortality is constant over time. We make detailed recommendations for improving the design of reward tagging studies in general.},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\2T4CV9PJ\\Pollock et al. - 2001 - Tag Reporting Rate Estimation 1. An Evaluation of.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\DS67LYZU\\1548-8675(2001)0210521TRREAE2.0.html}
}

@misc{pollock.ine2007,
  title = {The Design and Analysis of Field Studies to Estimate Catch and Release Mortality. {{Fisheries Management}} and {{Ecology}}},
  author = {Pollock, K. H. and Ine, W. E. P.},
  date = {2007},
  abstract = {mortality},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\ZP4M8JIG\\Pollock and Ine - 2007 - The design and analysis of field studies to estima.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\ST7K57MZ\\download.html}
}

@article{pollock.pine2007,
  title = {The Design and Analysis of Field Studies to Estimate Catch‐and‐release Mortality},
  author = {Pollock, Kenneth and Pine, William},
  date = {2007-04-01},
  journaltitle = {Fisheries Management and Ecology},
  shortjournal = {Fisheries Management and Ecology},
  volume = {14},
  pages = {123--130},
  doi = {10.1111/j.1365-2400.2007.00532.x},
  abstract = {Abstract The practice of catch and release (CR) as a fisheries management tool to reduce fishing mortality is widely applied in both freshwater and marine fisheries, whether from shifts in angler attitudes related to harvest or from the increasing use of harvest restrictions such as closed seasons or length limits. This approach assumes that for CR fishing policies to benefit the stock, CR will result in much lower mortality than would otherwise occur. There are many challenges in the design of CR studies to assess mortality, and in many practical settings it is difficult to obtain accurate and precise estimates. The focus of this article is on the design and quantitative aspects of estimating CR mortality, the need for a comprehensive approach that explicitly states all components of CR mortality, and the assumptions behind these methods. A general conceptual model for CR mortality that is applicable to containment and tagging-based studies with a slight modification is presented. This article reviews the design and analysis of containment and tagging studies to estimate CR mortality over both the short and long term and then compares these two approaches. Additionally, the potential population-level impacts of CR mortality are discussed. A recurring theme is the difficulty of designing studies to estimate CR mortality comprehensively and the need for additional research into both statistical model development and field study design.}
}

@article{ponisio.etal_2020,
  title = {One Size Does Not Fit All: {{Customizing MCMC}} Methods for Hierarchical Models Using {{NIMBLE}}},
  shorttitle = {One Size Does Not Fit All},
  author = {Ponisio, Lauren C. and family=Valpine, given=Perry, prefix=de, useprefix=true and Michaud, Nicholas and Turek, Daniel},
  date = {2020},
  journaltitle = {Ecology and Evolution},
  volume = {10},
  number = {5},
  pages = {2385--2416},
  issn = {2045-7758},
  doi = {10.1002/ece3.6053},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.6053},
  urldate = {2024-03-26},
  abstract = {Improved efficiency of Markov chain Monte Carlo facilitates all aspects of statistical analysis with Bayesian hierarchical models. Identifying strategies to improve MCMC performance is becoming increasingly crucial as the complexity of models, and the run times to fit them, increases. We evaluate different strategies for improving MCMC efficiency using the open-source software NIMBLE (R package nimble) using common ecological models of species occurrence and abundance as examples. We ask how MCMC efficiency depends on model formulation, model size, data, and sampling strategy. For multiseason and/or multispecies occupancy models and for N-mixture models, we compare the efficiency of sampling discrete latent states vs. integrating over them, including more vs. fewer hierarchical model components, and univariate vs. block-sampling methods. We include the common MCMC tool JAGS in comparisons. For simple models, there is little practical difference between computational approaches. As model complexity increases, there are strong interactions between model formulation and sampling strategy on MCMC efficiency. There is no one-size-fits-all best strategy, but rather problem-specific best strategies related to model structure and type. In all but the simplest cases, NIMBLE's default or customized performance achieves much higher efficiency than JAGS. In the two most complex examples, NIMBLE was 10–12 times more efficient than JAGS. We find NIMBLE is a valuable tool for many ecologists utilizing Bayesian inference, particularly for complex models where JAGS is prohibitively slow. Our results highlight the need for more guidelines and customizable approaches to fit hierarchical models to ensure practitioners can make the most of occupancy and other hierarchical models. By implementing model-generic MCMC procedures in open-source software, including the NIMBLE extensions for integrating over latent states (implemented in the R package nimbleEcology), we have made progress toward this aim.},
  langid = {english},
  keywords = {dynamic occupancy,latent states,Markov chain Monte Carlo,multispecies occupancy,N-mixture},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\VNEFRDQ3\\Ponisio et al. - 2020 - One size does not fit all Customizing MCMC method.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\TGWCXZNT\\ece3.html}
}

@article{pregler.etal_2019,
  title = {State-Space Analysis of Power to Detect Regional Brook Trout Population Trends over Time},
  author = {Pregler, Kasey C. and Hanks, R. Daniel and Childress, Evan S. and Hitt, Nathaniel P. and Hocking, Daniel J. and Letcher, Benjamin H. and Wagner, Tyler and Kanno, Yoichiro},
  date = {2019-11},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {76},
  number = {11},
  pages = {2145--2155},
  publisher = {NRC Research Press},
  issn = {0706-652X},
  doi = {10.1139/cjfas-2018-0241},
  url = {https://cdnsciencepub.com/doi/full/10.1139/cjfas-2018-0241},
  urldate = {2023-03-27},
  abstract = {Threats to aquatic biodiversity are expressed at broad spatial scales, but identifying regional trends in abundance is challenging owing to variable sampling designs and temporal and spatial variation in abundance. We compiled a regional data set of brook trout (Salvelinus fontinalis) counts across their southern range representing 326 sites from eight states between 1982 and 2014 and conducted a statistical power analysis using Bayesian state-space models to evaluate the ability to detect temporal trends by characterizing posterior distributions with three approaches. A combination of monitoring periods, number of sites and electrofishing passes, decline magnitude, and different revisit patterns were tested. Power increased with monitoring periods and decline magnitude. Trends in adults were better detected than young-of-the-year fish, which showed greater interannual variation in abundance. The addition of weather covariates to account for the temporal variation increased power only slightly. Single- and three-pass electrofishing methods were similar in power. Finally, power was higher for sampling designs with more frequent revisits over the duration of the monitoring program. Our results provide guidance for broad-scale monitoring designs for temporal trend detection.},
  file = {C:\Users\jhncsu\Zotero\storage\47AF2S6J\Pregler et al. - 2019 - State-space analysis of power to detect regional b.pdf}
}

@book{ricker1975,
  title = {Computation and Interpretation of Biological Statistics of Fish Populations},
  author = {Ricker, William Edwin},
  editora = {Canada and Canada},
  editoratype = {collaborator},
  date = {1975},
  series = {Bulletin},
  number = {191},
  publisher = {{Dept. of Fisheries and Oceans : Minister of Supply and Services Canada}},
  location = {Ottawa},
  isbn = {978-0-662-01440-9},
  pagetotal = {382},
  keywords = {Fish populations,Sampling (Statistics),Statistical methods},
  annotation = {OCLC: ocm20967850}
}

@book{ricker1978,
  title = {Computation and {{Interpretation}} of {{Biological Statistics}} of {{Fish Populations}}},
  author = {Ricker, William Edwin},
  date = {1978},
  eprint = {v6FNAQAAIAAJ},
  eprinttype = {googlebooks},
  publisher = {{Fisheries and Marine Service}},
  langid = {english},
  pagetotal = {410}
}

@article{robson.regier1964,
  title = {Sample {{Size}} in {{Petersen Mark}}–{{Recapture Experiments}}},
  author = {Robson, D. S. and Regier, H. A.},
  date = {1964},
  journaltitle = {Transactions of the American Fisheries Society},
  volume = {93},
  number = {3},
  pages = {215--226},
  issn = {1548-8659},
  doi = {10.1577/1548-8659(1964)93[215:SSIPME]2.0.CO;2},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1577/1548-8659%281964%2993%5B215%3ASSIPME%5D2.0.CO%3B2},
  urldate = {2022-01-27},
  abstract = {The efficient planning of a Petersen-type mark and recapture experiment requires some knowledge of the order of magnitude of the population size N. Sample sizes M and C of the mark and recapture samples, respectively, may then be ascertained on the basis of a guessed value of N to achieve any desired degree of accuracy with any specified degree of confidence. Restrictions on the sample sizes M and C are that MC must exceed 4 times the guessed value of N, and the total costs of M and C must be equal. Graphs and formulas are given defining sample size to attain preassigned levels of accuracy and precision of population estimation. A method of choosing sample sizes such that experimental costs are minimized is described.},
  langid = {english},
  file = {C:\Users\jhncsu\Zotero\storage\BTLL3EQF\1548-8659(1964)93[215SSIPME]2.0.html}
}

@incollection{royle.dorazio_2009,
  title = {Front {{Matter}}},
  booktitle = {Hierarchical {{Modeling}} and {{Inference}} in {{Ecology}}},
  editor = {Royle, J. Andrew and Dorazio, Robert M.},
  date = {2009-01-01},
  pages = {iii},
  publisher = {Academic Press},
  location = {San Diego},
  doi = {10.1016/B978-0-12-374097-7.50001-5},
  url = {https://www.sciencedirect.com/science/article/pii/B9780123740977500015},
  urldate = {2024-04-16},
  isbn = {978-0-12-374097-7},
  file = {C:\Users\jhncsu\Zotero\storage\K6MABBVK\B9780123740977500015.html}
}

@article{schaub.etal_2024,
  title = {Lessons to Be Learned by Comparing Integrated Fisheries Stock Assessment Models ({{SAMs}}) with Integrated Population Models ({{IPMs}})},
  author = {Schaub, Michael and Maunder, Mark N. and Kéry, Marc and Thorson, James T. and Jacobson, Eiren K. and Punt, André E.},
  date = {2024-04-01},
  journaltitle = {Fisheries Research},
  shortjournal = {Fisheries Research},
  volume = {272},
  pages = {106925},
  issn = {0165-7836},
  doi = {10.1016/j.fishres.2023.106925},
  url = {https://www.sciencedirect.com/science/article/pii/S0165783623003181},
  urldate = {2024-02-05},
  abstract = {Integrated fisheries stock assessment models (SAMs) and integrated population models (IPMs) are used in biological and ecological systems to estimate abundance and demographic rates. The approaches are fundamentally very similar, but historically have been considered as separate endeavors, resulting in a loss of shared vision, practice and progress. We review the two approaches to identify similarities and differences, with a view to identifying key lessons that would benefit more generally the overarching topic of population ecology. We present a case study for each of SAM (snapper from the west coast of New Zealand) and IPM (woodchat shrikes from Germany) to highlight differences and similarities. The key differences between SAMs and IPMs appear to be the objectives and parameter estimates required to meet these objectives, the size and spatial scale of the populations, and the differing availability of various types of data. In addition, up to now, typical SAMs have been applied in aquatic habitats, while most IPMs stem from terrestrial habitats. SAMs generally aim to assess the level of sustainable exploitation of fish populations, so absolute abundance or biomass must be estimated, although some estimate only relative trends. Relative abundance is often sufficient to understand population dynamics and inform conservation actions, which is the main objective of IPMs. IPMs are often applied to small populations of conservation concern, where demographic uncertainty can be important, which is more conveniently implemented using Bayesian approaches. IPMs are typically applied at small to moderate spatial scales (1 to 104 km2), with the possibility of collecting detailed longitudinal individual data, whereas SAMs are typically applied to large, economically valuable fish stocks at very large spatial scales (104 to 106 km2) with limited possibility of collecting detailed individual data. There is a sense in which a SAM is more data- (or information-) hungry than an IPM because of its goal to estimate absolute biomass or abundance, and data at the individual level to inform demographic rates are more difficult to obtain in the (often marine) systems where most SAMs are applied. SAMs therefore require more 'tuning' or assumptions than IPMs, where the 'data speak for themselves', and consequently techniques such as data weighting and model evaluation are more nuanced for SAMs than for IPMs. SAMs would benefit from being fit to more disaggregated data to quantify spatial and individual variation and allow richer inference on demographic processes. IPMs would benefit from more attempts to estimate absolute abundance, for example by using unconditional models for capture-recapture data.},
  keywords = {Data integration,Management,Parameter estimation,Population dynamics,Population model,Uncertainty},
  file = {C:\Users\jhncsu\Zotero\storage\8T7MY84K\S0165783623003181.html}
}

@article{scherrer.etal2021,
  title = {Estimation of Growth Parameters Integrating Tag-Recapture, Length-Frequency, and Direct Aging Data Using Likelihood and {{Bayesian}} Methods for the Tropical Deepwater Snapper {{Pristipomoides}} Filamentosus in {{Hawaii}}},
  author = {Scherrer, Stephen R. and Kobayashi, Donald R. and Weng, Kevin C. and Okamoto, Henry Y. and Oishi, Francis G. and Franklin, Erik C.},
  date = {2021-01},
  journaltitle = {Fisheries Research},
  shortjournal = {Fisheries Research},
  volume = {233},
  pages = {105753},
  issn = {01657836},
  doi = {10.1016/j.fishres.2020.105753},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165783620302708},
  urldate = {2023-02-07},
  abstract = {Pristipomoides filamentosus is an economically and culturally important species of deepwater snapper found throughout the tropical Indo-Pacific. From 1989–1993, the State of Hawaii initiated a tagging program with fish opportunistically recaptured by scientists and fishers to quantify growth and other life history parameters. Over approximately 10 years, 10.5 \% of 4179 tagged P. filamentosus were recaptured. We used these data to compare von Bertalanffy growth parameters estimated using Bayesian and likelihood approaches. Next, we defined an objective cost function to estimate growth parameters that integrated the tagging data with direct aging and length frequency data used in previous regional growth studies. Our results reconcile 30+ years of effort from various methods to estimate growth parameters for P. filametosus in Hawaii (L∞ = 68.14 cm FL [95 \% Confidence Interval (CI): 65.42–69.54] and K = 0.22 yr− 1 [CI: 0.20–0.25]), demonstrate the importance of individual variability in the species due primarily to the asymptotic length parameter L∞, and suggest the effects of sexual dimorphism on growth as a focus of future inquiry. These results have direct management implications as growth is a critical input for age-based stock assessment models and often used as a proxy for other life history traits.},
  langid = {english},
  file = {C:\Users\jhncsu\Zotero\storage\QTXTQW95\Scherrer et al. - 2021 - Estimation of growth parameters integrating tag-re.pdf}
}

@article{scherrer.etal2021a,
  title = {Estimation of Growth Parameters Integrating Tag-Recapture, Length-Frequency, and Direct Aging Data Using Likelihood and {{Bayesian}} Methods for the Tropical Deepwater Snapper {{Pristipomoides}} Filamentosus in {{Hawaii}}},
  author = {Scherrer, Stephen R. and Kobayashi, Donald R. and Weng, Kevin C. and Okamoto, Henry Y. and Oishi, Francis G. and Franklin, Erik C.},
  date = {2021-01-01},
  journaltitle = {Fisheries Research},
  shortjournal = {Fisheries Research},
  volume = {233},
  pages = {105753},
  issn = {0165-7836},
  doi = {10.1016/j.fishres.2020.105753},
  url = {https://www.sciencedirect.com/science/article/pii/S0165783620302708},
  urldate = {2023-02-16},
  abstract = {Pristipomoides filamentosus is an economically and culturally important species of deepwater snapper found throughout the tropical Indo-Pacific. From 1989–1993, the State of Hawaii initiated a tagging program with fish opportunistically recaptured by scientists and fishers to quantify growth and other life history parameters. Over approximately 10 years, 10.5 \% of 4179 tagged P. filamentosus were recaptured. We used these data to compare von Bertalanffy growth parameters estimated using Bayesian and likelihood approaches. Next, we defined an objective cost function to estimate growth parameters that integrated the tagging data with direct aging and length frequency data used in previous regional growth studies. Our results reconcile 30+ years of effort from various methods to estimate growth parameters for P. filametosus in Hawaii (L∞ = 68.14 cm FL [95 \% Confidence Interval (CI): 65.42–69.54] and K = 0.22 yr−1 [CI: 0.20–0.25]), demonstrate the importance of individual variability in the species due primarily to the asymptotic length parameter L∞, and suggest the effects of sexual dimorphism on growth as a focus of future inquiry. These results have direct management implications as growth is a critical input for age-based stock assessment models and often used as a proxy for other life history traits.},
  langid = {english},
  keywords = {Bayesian,Integrated model,Maximum Likelihood,von Bertalanffy growth},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\EGN6V7DE\\Scherrer et al. - 2021 - Estimation of growth parameters integrating tag-re.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\7RIL42JI\\S0165783620302708.html}
}

@article{spiegelhalter.etal_2002,
  title = {Bayesian Measures of Model Complexity and Fit},
  author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and Van Der Linde, Angelika},
  date = {2002},
  journaltitle = {Journal of the Royal Statistical Society. Series B, Statistical methodology},
  volume = {64},
  number = {4},
  pages = {583--639},
  publisher = {Blackwell Publishers},
  location = {Oxford, UK},
  issn = {1369-7412},
  doi = {10.1111/1467-9868.00353},
  url = {https://ncsu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1Lb9NAEB6h5lIJ8SzCPIwPCHExtb12vHtsLNKeKiCgCi6rXXutltIkil1U_j0z49gkERIgDo6daO1NZue1k5lvAETyJgp3dEJVoRqMFbIH2gM0gSbKnaxKpSpT12m2E9vp2p5SaUwHFzHE30hQWH2TvBvb9DJ_yPKu5JgSI0VG4J84C0HpTz7LTcUsujIsFaIhTdZIP7-5f8tIjYjeN32-IiVPmgbpV3eNL7Y809HKLV25Y8O23V62W9O7cNn_RE5XoSYJm3n7h4yVyAAZPS7kf5DjHtxZu7fBUceP9-GWmz-AffJoO0DohxBOzA9HlZvBVReebIJFHXBDnoDz290NbgwCM6-C-qI9gE_Ttx-Lk3DdsyEsM_QckK45dbNGyytLXNfI1lmCLowjYLDa5TW-UbaWUSVlakuZmTjJq8hJAj5F5WzFI7htKLd_3nINYPUYAvT_jcDnlMQrqXQqtdZkeexspErhEg9e96ullx1Gh-73NkQJTZTQTAkPXvFqDuPM6pJS2_JMn50e6_dnJyKevTvWUw8OeLmHgQLVsYzGHvhby_9rQvL0kOc8eNHzg0ZJpb9fzNwtrhstFNUp5_h1C2aT4Vb7zXxdrJrG6u9amHGKLzifofQZPF3gQR8t8cik0OhS6vP2yoOXm0w2PIwRkFRC-3q69CD-m2HFGhCegBBaD0JmrT8RU3-YzSZ4fvKP45_CPvfU4UDWM9hrV9fuOewR7_swOiqKL6c-S67PkRafUa9_ApW0Qv8},
  urldate = {2023-12-06},
  abstract = {We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure P-D for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general P-D approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the 'hat' matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding P-D to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.;We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pD for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pD approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the ‘hat’ matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.;We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure "p""D" for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general "p""D" approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the 'hat' matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding "p""D" to the posterior mean deviance gives a "deviance information criterion" for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis. Copyright 2002 Royal Statistical Society.;Summary We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pD for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pD approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the ‘hat’ matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.;We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pDfor the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pDapproximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the 'hat' matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pDto the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.;},
  langid = {english},
  keywords = {Approximation,Bayesian method,Bayesian model comparison,Bayesian networks,Decision theory,Deviance,Deviance information criterion,Effective number of parameters,Estimators,Exact sciences and technology,Hierarchical models,Information theory,Leverage,Markov chain Monte Carlo methods,Markovian processes,Mathematics,Model dimension,Modeling,Monte Carlo simulation,Multilevel models,Parameterization,Parametric models,Physical Sciences,Predictive modeling,Probability and statistics,Sample size,Science & Technology,Sciences and techniques of general use,Spatial models,Statistical methods,Statistical models,Statistics,Statistics & Probability},
  file = {C:\Users\jhncsu\Zotero\storage\AJYLK79X\Spiegelhalter et al. - 2002 - Bayesian measures of model complexity and fit.pdf}
}

@article{stich.etal_2015,
  title = {Life, {{Death}}, and {{Resurrection}}: {{Accounting}} for {{State Uncertainty}} in {{Survival Estimation}} from {{Tagged Grass Carp}}},
  shorttitle = {Life, {{Death}}, and {{Resurrection}}},
  author = {Stich, Daniel S. and Jiao, Yan and Murphy, Brian R.},
  date = {2015},
  journaltitle = {North American Journal of Fisheries Management},
  volume = {35},
  number = {2},
  pages = {321--330},
  issn = {1548-8675},
  doi = {10.1080/02755947.2014.996685},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1080/02755947.2014.996685},
  urldate = {2024-01-14},
  abstract = {Information about Grass Carp Ctenopharyngodon idella survival would be useful for improving the management of fish used for aquatic weed control. Reliable methods for estimating annual poststocking survival of Grass Carp from radiotelemetry data do not exist because the fish remain sedentary for prolonged periods between movements, giving the false impression of death, only to be observed alive (i.e., “resurrected”) at a later date. We constructed a state-space, multistate mark–recapture survival model accounting for uncertainty in the live/dead states of tagged Grass Carp in a large (8,500 ha) reservoir, and we estimated monthly and annual survival. Model results were compared with life history-based methods for estimating survival, and survival estimates that were corrected for state misclassification were compared with uncorrected estimates. Corrected estimates of annual survival (mean = 0.23; 95\% credible interval [CRI] = 0.15–0.41) contained less bias than uncorrected estimates (0.12; 95\% CRI = 0.08–0.18). However, both corrected and uncorrected estimates were substantially lower than the survival expected based on life history theory (mean = 0.69; 95\% confidence interval = 0.52–0.78), suggesting that mark–recapture survival estimates for Grass Carp might be negatively biased due to tag shedding, tag-related mortality, or both. Our model effectively reduced bias in monthly and annual survival estimates due to state misclassification, illustrating the potential for application of existing mark–recapture frameworks to estimate Grass Carp survival with telemetry data, despite the behavioral idiosyncrasies of the species. Furthermore, these methods may have application for studies of other animals that undergo periodic quiescence between movements, such as salmonids, ictalurids, and reef fishes. To account for bias resulting from tag loss, future mark–recapture studies of Grass Carp could incorporate tag shedding rates within the framework developed here. Received July 19, 2014; accepted December 3, 2014},
  langid = {english},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\PI3I9GWB\\Stich et al. - 2015 - Life, Death, and Resurrection Accounting for Stat.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\YSPDAC93\\02755947.2014.html}
}

@article{vetter1988,
  title = {Estimation of {{Natural Mortality}} in {{Fish Stocks}} - a {{Review}}},
  author = {Vetter, Ef},
  date = {1988-01},
  journaltitle = {Fishery Bulletin},
  shortjournal = {Fish. Bull.},
  volume = {86},
  number = {1},
  pages = {25--43},
  publisher = {Natl Marine Fisheries Service Scientific Publ Office},
  location = {Seattle},
  issn = {0090-0656},
  url = {http://www.webofscience.com/wos/woscc/full-record/WOS:A1988P107100002},
  urldate = {2022-05-02},
  langid = {english},
  annotation = {WOS:A1988P107100002}
}

@article{wang.etal1995,
  title = {A Maximum Likelihood Approach for Estimating Growth from Tag–Recapture Data},
  author = {Wang, You-Gan and Thomas, Mervyn R. and Somers, Ian F.},
  date = {1995-02-01},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {52},
  number = {2},
  pages = {252--259},
  issn = {0706-652X, 1205-7533},
  doi = {10.1139/f95-025},
  url = {http://www.nrcresearchpress.com/doi/10.1139/f95-025},
  urldate = {2023-03-07},
  abstract = {The Fabens method is commonly used to estimate growth parameters \&I and 1, in the von Bertalanffy model from tag-recapture data. However, the Fabens method s f estimation has an inherent bias when individual growth is variable. This paper presents an asymptotically unbiassed method using a maximum likelihood approach that takes account s f individual variability in both maximum length and age-at-tagging. It is assumed that each individual's growth follows a von Bertalanffy curve with its own maximum length and age-at-tagging. The parameter k is assumed to be a constant to ensure that the mean growth follows a von Bertalanffy curve and to avoid overparameterizatkm. Our method also makes more efficient use sf the measurements at tag and recapture and includes diagnostic techniques for checking distributional assumptions. The method is reasonably robust and performs better than the Fabens method when individual growth differs from the von Bertalanffy relationship. When measurement error is negligible, the estimation involves maximizing the profile likelihood of one parameter only. The method is applied to tag-recapture data for the grooved tiger prawn (Penaeus semisukcatus) from the Gulf of Carpentaria, Australia.},
  langid = {english},
  file = {C:\Users\jhncsu\Zotero\storage\559SLQIM\Wang et al. - 1995 - A maximum likelihood approach for estimating growt.pdf}
}

@article{wang1997,
  title = {Comment: {{Efficiency}} and Bias of Estimators and Sampling Designs for Determining Lengthweight Relationships of Fishes},
  shorttitle = {Comment},
  author = {Wang, Y -G},
  date = {1997-03},
  journaltitle = {Canadian Journal of Fisheries and Aquatic Sciences},
  shortjournal = {Can. J. Fish. Aquat. Sci.},
  volume = {54},
  number = {3},
  pages = {742--743},
  publisher = {NRC Research Press},
  issn = {0706-652X},
  doi = {10.1139/f96-298},
  url = {https://cdnsciencepub.com/doi/abs/10.1139/f96-298},
  urldate = {2023-02-20},
  file = {C:\Users\jhncsu\Zotero\storage\X25TGGNS\Wang - 1997 - Comment Efficiency and bias of estimators and sam.pdf}
}

@book{xie2015,
  title = {Dynamic {{Documents}} with {{R}} and Knitr},
  author = {Xie, Yihui},
  date = {2015},
  edition = {2},
  publisher = {{Chapman and Hall/CRC}},
  location = {Boca Raton, Florida},
  url = {http://yihui.name/knitr/}
}

@article{zhang.etal2009,
  title = {Use of {{Bayesian}} Hierarchical Models to Estimate Northern Abalone, {{Haliotis}} Kamtschatkana, Growth Parameters from Tag-Recapture Data},
  author = {Zhang, Zane and Lessard, Joanne and Campbell, Alan},
  date = {2009-01-14},
  journaltitle = {Fisheries Research},
  shortjournal = {Fisheries Research},
  volume = {95},
  number = {2},
  pages = {289--295},
  issn = {0165-7836},
  doi = {10.1016/j.fishres.2008.09.035},
  url = {https://www.sciencedirect.com/science/article/pii/S0165783608003184},
  urldate = {2023-02-16},
  abstract = {Bayesian hierarchical models were developed to estimate the growth parameters of northern abalone, Haliotis kamtschatkana, using tag-recapture data with a mixture of single and multiple recaptures. Individual variability in the growth parameters L∞ and k of the von Bertalanffy model was incorporated in the analyses. The models developed fit the data well based on the Bayesian p-values. Variability in L∞ for individuals was high relative to the variability in L∞ for the population, and variability in k for individuals was about the same as the variability in k for the population. Simulations showed that estimates of the growth parameters were accurate (relative biases {$<$}5\%), when variability in both L∞ and k or just in L∞ was accounted for. The “true” values of the parameters, L∞ and k, were contained in the estimated 95\% credibility intervals in 90–94 out of 100 simulation runs on 100 simulated data sets. Overall, allowing for variability for both L∞ and k resulted in moderately more accurate estimates than allowing for just L∞. On the contrary, estimates were unreliable when variability in just k was considered. Using the WinBUGS software program, the calculation procedure was rather simple irrespective of which growth parameter was modeled with variability.},
  langid = {english},
  keywords = {Abalone,Bayesian,Growth,Hierarchical,Simulation,Variability},
  file = {C\:\\Users\\jhncsu\\Zotero\\storage\\4VZRC2SA\\Zhang et al. - 2009 - Use of Bayesian hierarchical models to estimate no.pdf;C\:\\Users\\jhncsu\\Zotero\\storage\\4DL2I4AQ\\S0165783608003184.html}
}
